=================config=================
add_bc_loss: 0
batch_size: 256
bc_policy: ''
discount: 0.99
end_on_success: 1
env_reward_scale: 1
episode_length: 300
freeze_bc_replay: 1
image_size: 224
load_policy_only: 0
load_pretrained_agent: release/model/robomimic/square_cql_less/model0.pt
load_ref_agent: ''
log_per_step: 5
mix_rl_rate: 1
mp_eval: 0
nstep: 3
num_critic_update: 5
num_eval_episode: 10
num_train_step: 300000
num_warm_up_episode: 100
obs_stack: 1
preload_datapath: release/data/robomimic/square/processed_data96.hdf5
preload_num_data: 100
pretrain_epoch_len: 10000
pretrain_num_epoch: 20
pretrain_only: 1
prop_stack: 1
q_agent:
  act_method: cql
  actor:
    dropout: 0
    feature_dim: 128
    hidden_dim: 1024
    max_action_norm: -1
    orth: 1
    spatial_emb: 0
  awac_beta: 1.0
  bc_loss_coef: 0.1
  bc_loss_dynamic: 0
  bootstrap_method: cql
  cql_weight: 1.0
  critic:
    drop: 0
    feature_dim: 128
    fuse_patch: 1
    hidden_dim: 1024
    norm_weight: 0
    orth: 1
    spatial_emb: 0
  critic_target_tau: 0.01
  device: cuda
  enc_type: vit
  entropy_weight: 1.0
  ibrl_eps_greedy: 1
  lr: 0.0001
  min_q_weight: 1.0
  num_random_actions: 4
  resnet:
    downsample: default
    norm_layer: gnn
    shallow: 0
    stem: default
  resnet96:
    shallow: 0
    use_1x1: 0
  soft_ibrl_beta: 10
  state_actor:
    dropout: 0.5
    hidden_dim: 1024
    layer_norm: 0
    num_layer: 3
    orth: 0
  state_critic:
    append_action: 0
    dropout: 0.0
    hidden_dim: 1024
    layer_norm: 1
    num_k: 2
    num_layer: 3
    num_q: 5
    orth: 0
  stddev_clip: 0.3
  target_q_gap: 5.0
  use_prop: 0
  vit:
    depth: 3
    embed_dim: 128
    embed_norm: 0
    embed_style: embed1
    num_heads: 4
    patch_size: 8
    stride: -1
record_dir: null
replay_buffer_size: 1000
rl_camera: agentview+robot0_eye_in_hand
rl_image_size: 96
save_dir: exp/compare/square_cql_test
save_per_success: -1
seed: 1
state_stack: 3
stddev_max: 0.1
stddev_min: 0.1
stddev_step: 500000
task_name: NutAssemblySquare
update_freq: 2
use_state: 1
use_wb: 0
========================================
rl_cameras: []
(69,)
=============critic weights=============
MultiFcQ(
  (net): Sequential(
    (0): _MultiLinear(76 x 1024, 5 nets)
    (1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
    (2): ReLU()
    (3): _MultiLinear(1024 x 1024, 5 nets)
    (4): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
    (5): ReLU()
    (6): _MultiLinear(1024 x 1024, 5 nets)
    (7): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
    (8): ReLU()
    (9): _MultiLinear(1024 x 1, 5 nets)
  )
)
| Module        |    #Params |      % |
|---------------+------------+--------|
| net.0.weights |    389,120 |   3.57 |
| net.0.biases  |          5 |   0.00 |
| net.1.weight  |      1,024 |   0.01 |
| net.1.bias    |      1,024 |   0.01 |
| net.3.weights |  5,242,880 |  48.16 |
| net.3.biases  |          5 |   0.00 |
| net.4.weight  |      1,024 |   0.01 |
| net.4.bias    |      1,024 |   0.01 |
| net.6.weights |  5,242,880 |  48.16 |
| net.6.biases  |          5 |   0.00 |
| net.7.weight  |      1,024 |   0.01 |
| net.7.bias    |      1,024 |   0.01 |
| net.9.weights |      5,120 |   0.05 |
| net.9.biases  |          5 |   0.00 |
| Total         | 10,886,164 | 100.00 |
=============actor weights==============
FcActor(
  (net): Sequential(
    (0): Linear(in_features=69, out_features=1024, bias=True)
    (1): Dropout(p=0.5, inplace=False)
    (2): ReLU()
    (3): Linear(in_features=1024, out_features=1024, bias=True)
    (4): Dropout(p=0.5, inplace=False)
    (5): ReLU()
    (6): Linear(in_features=1024, out_features=1024, bias=True)
    (7): Dropout(p=0.5, inplace=False)
    (8): ReLU()
    (9): Linear(in_features=1024, out_features=7, bias=True)
    (10): Tanh()
  )
)
| Module       |   #Params |      % |
|--------------+-----------+--------|
| net.0.weight |    70,656 |   3.24 |
| net.0.bias   |     1,024 |   0.05 |
| net.3.weight | 1,048,576 |  48.14 |
| net.3.bias   |     1,024 |   0.05 |
| net.6.weight | 1,048,576 |  48.14 |
| net.6.bias   |     1,024 |   0.05 |
| net.9.weight |     7,168 |   0.33 |
| net.9.bias   |         7 |   0.00 |
| Total        | 2,178,055 | 100.00 |
loading loading pretrained agent from release/model/robomimic/square_cql_less/model0.pt
loading first 100 episodes from release/data/robomimic/square/processed_data96.hdf5
Raw Dataset size (#episode): 50
episode 0 length: 127
episode 1 length: 123
episode 2 length: 124
episode 3 length: 149
episode 4 length: 154
episode 5 length: 144
episode 6 length: 144
episode 7 length: 150
episode 8 length: 160
episode 9 length: 152
episode 10 length: 134
episode 11 length: 156
episode 12 length: 133
episode 13 length: 153
episode 14 length: 152
episode 15 length: 141
episode 16 length: 174
episode 17 length: 174
episode 18 length: 127
episode 19 length: 165
episode 20 length: 145
episode 21 length: 179
episode 22 length: 130
episode 23 length: 176
episode 24 length: 155
episode 25 length: 158
episode 26 length: 182
episode 27 length: 180
episode 28 length: 136
episode 29 length: 183
episode 30 length: 134
episode 31 length: 139
episode 32 length: 142
episode 33 length: 120
episode 34 length: 129
episode 35 length: 174
episode 36 length: 147
episode 37 length: 160
episode 38 length: 114
episode 39 length: 128
episode 40 length: 140
episode 41 length: 134
episode 42 length: 186
episode 43 length: 122
episode 44 length: 125
episode 45 length: 180
episode 46 length: 132
episode 47 length: 148
episode 48 length: 170
episode 49 length: 167
Size of the replay buffer: 50, # success: 50
Size of the bc_replay buffer: 50
demo actions shape: (7451, 7)
demo action norm: mean: 0.5958, max: 1.6995
loading first 50 episodes from release/data/robomimic/square/processed_data96.hdf5
Raw Dataset size (#episode): 50
episode 0 length: 127
episode 1 length: 123
episode 2 length: 124
episode 3 length: 149
episode 4 length: 154
episode 5 length: 144
episode 6 length: 144
episode 7 length: 150
episode 8 length: 160
episode 9 length: 152
episode 10 length: 134
episode 11 length: 156
episode 12 length: 133
episode 13 length: 153
episode 14 length: 152
episode 15 length: 141
episode 16 length: 174
episode 17 length: 174
episode 18 length: 127
episode 19 length: 165
episode 20 length: 145
episode 21 length: 179
episode 22 length: 130
episode 23 length: 176
episode 24 length: 155
episode 25 length: 158
episode 26 length: 182
episode 27 length: 180
episode 28 length: 136
episode 29 length: 183
episode 30 length: 134
episode 31 length: 139
episode 32 length: 142
episode 33 length: 120
episode 34 length: 129
episode 35 length: 174
episode 36 length: 147
episode 37 length: 160
episode 38 length: 114
episode 39 length: 128
episode 40 length: 140
episode 41 length: 134
episode 42 length: 186
episode 43 length: 122
episode 44 length: 125
episode 45 length: 180
episode 46 length: 132
episode 47 length: 148
episode 48 length: 170
episode 49 length: 167
Size of the replay buffer: 50, # success: 50
demo actions shape: (7451, 7)
demo action norm: mean: 0.5958, max: 1.6995
Pretraining
mean var:31.21927261352539,max:3247.431396484375,min:0.0612797848880291
[0] Time spent = 275.47 s
0: pretrain/score     : 0.00
0: data/batch_R       [10000]: avg:   0.0205, min:   0.0000[2835], max:   0.0522[6017]
0: train/actor_loss   [10000]: avg: 798.1569, min: 719.8846[ 562], max: 867.9769[9926]
0: train/critic_loss  [10000]: avg: 228.2116, min:   3.6231[2551], max: 2288.9763[6845]
0: train/critic_qt    [10000]: avg: -755.7379, min: -828.8578[8721], max: -679.6488[ 810]
0: train/td_loss      [10000]: avg: 256.2575, min:  31.2375[2818], max: 2319.6074[6845]
Saved model to exp/compare/square_cql_test/model0.pt
saved?: True
Mem info: used: 2.400 GB, avail: 54.963 GB, total: 62.538 GB
mean var:27.80535125732422,max:4190.31787109375,min:0.07060745358467102
[1] Time spent = 275.02 s
1: pretrain/score     : 0.00
1: data/batch_R       [10000]: avg:   0.0205, min:   0.0019[5301], max:   0.0522[4293]
1: train/actor_loss   [10000]: avg: 871.2576, min: 486.6674[9994], max: 967.8804[8300]
1: train/critic_loss  [10000]: avg: 425.2903, min:  17.0737[3945], max: 22750.7812[9260]
1: train/critic_qt    [10000]: avg: -829.2008, min: -915.6456[8695], max: -492.7241[9971]
1: train/td_loss      [10000]: avg: 447.8863, min:  45.7947[3945], max: 22716.2871[9260]
Saved model to exp/compare/square_cql_test/model1.pt
saved?: True
Mem info: used: 2.561 GB, avail: 54.814 GB, total: 62.538 GB
mean var:59.22671127319336,max:2896.82470703125,min:0.039085693657398224
[2] Time spent = 276.81 s
2: pretrain/score     : 0.00
2: data/batch_R       [10000]: avg:   0.0205, min:   0.0038[ 463], max:   0.0463[3429]
2: train/actor_loss   [10000]: avg: 323.5054, min: 253.7591[2224], max: 548.8889[  11]
2: train/critic_loss  [10000]: avg: 171.7412, min:  27.6475[7984], max: 1876.6207[ 313]
2: train/critic_qt    [10000]: avg: -304.0959, min: -556.5561[  11], max: -233.7784[2224]
2: train/td_loss      [10000]: avg: 182.6795, min:  42.7703[5369], max: 1859.0101[ 313]
Saved model to exp/compare/square_cql_test/model2.pt
saved?: True
Mem info: used: 2.582 GB, avail: 54.792 GB, total: 62.538 GB
mean var:2.386549949645996,max:12.293771743774414,min:0.02004210464656353
[3] Time spent = 276.14 s
3: pretrain/score     : 0.00
3: data/batch_R       [10000]: avg:   0.0205, min:   0.0019[3140], max:   0.0541[9980]
3: train/actor_loss   [10000]: avg: 363.7614, min: 326.6821[2233], max: 398.5743[9636]
3: train/critic_loss  [10000]: avg:  62.2853, min:  12.4683[8852], max: 437.6069[2391]
3: train/critic_qt    [10000]: avg: -340.3364, min: -373.4455[9992], max: -303.8453[2233]
3: train/td_loss      [10000]: avg:  79.8870, min:  30.9085[8852], max: 455.3526[2391]
Saved model to exp/compare/square_cql_test/model3.pt
saved?: True
Mem info: used: 2.582 GB, avail: 54.815 GB, total: 62.538 GB
mean var:2.543631076812744,max:19.780174255371094,min:0.04308953136205673
[4] Time spent = 319.54 s
4: pretrain/score     : 0.00
4: data/batch_R       [10000]: avg:   0.0205, min:   0.0019[4060], max:   0.0484[7195]
4: train/actor_loss   [10000]: avg: 382.8594, min: 341.6194[1682], max: 418.1964[9766]
4: train/critic_loss  [10000]: avg:  49.6349, min:  10.6989[7434], max: 415.2965[4866]
4: train/critic_qt    [10000]: avg: -358.3404, min: -391.1015[9766], max: -317.5506[1682]
4: train/td_loss      [10000]: avg:  68.7346, min:  30.8512[7434], max: 432.5838[4866]
Saved model to exp/compare/square_cql_test/model4.pt
saved?: True
Mem info: used: 2.582 GB, avail: 53.268 GB, total: 62.538 GB
mean var:1.608227252960205,max:11.061332702636719,min:0.005920625291764736
[5] Time spent = 274.52 s
5: pretrain/score     : 0.10
5: data/batch_R       [10000]: avg:   0.0204, min:   0.0000[1447], max:   0.0504[ 112]
5: train/actor_loss   [10000]: avg: 394.5854, min: 359.2047[ 768], max: 428.3076[9852]
5: train/critic_loss  [10000]: avg:  42.5879, min:   8.3580[9470], max: 555.4648[9024]
5: train/critic_qt    [10000]: avg: -369.3900, min: -401.1693[9690], max: -333.0562[ 768]
5: train/td_loss      [10000]: avg:  62.6926, min:  28.4570[9470], max: 576.9806[9024]
Saved model to exp/compare/square_cql_test/model5.pt
saved?: True
Mem info: used: 2.582 GB, avail: 53.259 GB, total: 62.538 GB
mean var:1.7247183322906494,max:9.060163497924805,min:0.03254995495080948
[6] Time spent = 276.53 s
6: pretrain/score     : 0.00
6: data/batch_R       [10000]: avg:   0.0205, min:   0.0020[4017], max:   0.0483[2278]
6: train/actor_loss   [10000]: avg: 407.8884, min: 373.3637[3455], max: 437.7687[4859]
6: train/critic_loss  [10000]: avg:  37.7442, min:   6.8273[6062], max: 587.2369[5185]
6: train/critic_qt    [10000]: avg: -382.0822, min: -411.6465[2045], max: -349.3927[3455]
6: train/td_loss      [10000]: avg:  58.5915, min:  27.7837[6062], max: 608.5492[5185]
Saved model to exp/compare/square_cql_test/model6.pt
saved?: True
Mem info: used: 2.583 GB, avail: 54.779 GB, total: 62.538 GB
mean var:2.349637985229492,max:12.000940322875977,min:0.0823688730597496
[7] Time spent = 285.52 s
7: pretrain/score     : 0.00
7: data/batch_R       [10000]: avg:   0.0205, min:   0.0019[5865], max:   0.0522[ 748]
7: train/actor_loss   [10000]: avg: 414.9385, min: 379.9797[ 269], max: 447.0457[9647]
7: train/critic_loss  [10000]: avg:  35.0936, min:   5.1882[9056], max: 458.7639[8087]
7: train/critic_qt    [10000]: avg: -388.7513, min: -421.8510[3501], max: -352.9915[ 269]
7: train/td_loss      [10000]: avg:  56.6092, min:  27.2638[9056], max: 480.7997[8087]
Saved model to exp/compare/square_cql_test/model7.pt
saved?: True
Mem info: used: 2.634 GB, avail: 53.187 GB, total: 62.538 GB
mean var:1.8405295610427856,max:24.819305419921875,min:0.016976742073893547
[8] Time spent = 338.18 s
8: pretrain/score     : 0.10
8: data/batch_R       [10000]: avg:   0.0204, min:   0.0019[1860], max:   0.0483[7966]
8: train/actor_loss   [10000]: avg: 423.7957, min: 391.3546[2519], max: 453.4652[8989]
8: train/critic_loss  [10000]: avg:  32.1641, min:   5.3166[7409], max: 583.1343[2337]
8: train/critic_qt    [10000]: avg: -397.1313, min: -426.2631[8610], max: -366.1806[2519]
8: train/td_loss      [10000]: avg:  54.2555, min:  27.6337[2071], max: 604.9628[2337]
Saved model to exp/compare/square_cql_test/model8.pt
saved?: True
Mem info: used: 2.634 GB, avail: 52.939 GB, total: 62.538 GB
mean var:1.4659039974212646,max:13.459817886352539,min:0.02026154100894928
[9] Time spent = 290.15 s
9: pretrain/score     : 0.20
9: data/batch_R       [10000]: avg:   0.0204, min:   0.0019[2153], max:   0.0483[1732]
9: train/actor_loss   [10000]: avg: 431.5737, min: 394.0550[4120], max: 463.9016[9144]
9: train/critic_loss  [10000]: avg:  30.9752, min:   2.1729[3836], max: 550.0283[2179]
9: train/critic_qt    [10000]: avg: -404.5003, min: -436.7018[9144], max: -367.4905[4120]
9: train/td_loss      [10000]: avg:  53.5807, min:  25.4320[3836], max: 572.1852[2179]
Saved model to exp/compare/square_cql_test/model9.pt
saved?: True
Mem info: used: 2.634 GB, avail: 54.763 GB, total: 62.538 GB
mean var:1.1499912738800049,max:11.19126033782959,min:0.042877037078142166
[10] Time spent = 294.17 s
10: pretrain/score     : 0.10
10: data/batch_R       [10000]: avg:   0.0205, min:   0.0000[6138], max:   0.0503[3245]
10: train/actor_loss   [10000]: avg: 437.7538, min: 405.4851[ 345], max: 471.3158[3171]
10: train/critic_loss  [10000]: avg:  29.7644, min:   2.2751[9116], max: 522.4493[5103]
10: train/critic_qt    [10000]: avg: -410.3639, min: -443.2997[9715], max: -376.1986[ 653]
10: train/td_loss      [10000]: avg:  52.8323, min:  25.7245[9116], max: 545.3625[5103]
Saved model to exp/compare/square_cql_test/model10.pt
saved?: True
Mem info: used: 2.634 GB, avail: 53.207 GB, total: 62.538 GB
mean var:1.208109736442566,max:6.469351768493652,min:0.005456660408526659
[11] Time spent = 276.82 s
11: pretrain/score     : 0.00
11: data/batch_R       [10000]: avg:   0.0204, min:   0.0019[ 605], max:   0.0522[9638]
11: train/actor_loss   [10000]: avg: 440.5010, min: 404.0137[6112], max: 476.2692[1166]
11: train/critic_loss  [10000]: avg:  25.7623, min:  -0.2304[4157], max: 602.8052[8758]
11: train/critic_qt    [10000]: avg: -412.9645, min: -448.3088[1166], max: -378.1953[3488]
11: train/td_loss      [10000]: avg:  49.2084, min:  23.7640[4157], max: 626.2781[8758]
Saved model to exp/compare/square_cql_test/model11.pt
saved?: True
Mem info: used: 2.633 GB, avail: 53.329 GB, total: 62.538 GB
mean var:1.4240012168884277,max:12.287616729736328,min:0.006793207488954067
[12] Time spent = 490.32 s
12: pretrain/score     : 0.10
12: data/batch_R       [10000]: avg:   0.0206, min:   0.0000[4097], max:   0.0502[5994]
12: train/actor_loss   [10000]: avg: 444.1760, min: 410.8820[3041], max: 473.8490[8063]
12: train/critic_loss  [10000]: avg:  25.6087, min:   0.6946[6556], max: 580.1504[8526]
12: train/critic_qt    [10000]: avg: -416.4028, min: -445.0880[8063], max: -384.0430[ 840]
12: train/td_loss      [10000]: avg:  49.4174, min:  25.2765[6556], max: 603.7905[8526]
Saved model to exp/compare/square_cql_test/model12.pt
saved?: True
Mem info: used: 2.638 GB, avail: 53.007 GB, total: 62.538 GB
mean var:1.425234079360962,max:11.561433792114258,min:0.028200332075357437
[13] Time spent = 500.99 s
13: pretrain/score     : 0.10
13: data/batch_R       [10000]: avg:   0.0205, min:   0.0019[9618], max:   0.0465[1328]
13: train/actor_loss   [10000]: avg: 447.0886, min: 408.2587[2215], max: 481.7017[1606]
13: train/critic_loss  [10000]: avg:  24.6098, min:   1.0855[6183], max: 826.6924[3672]
13: train/critic_qt    [10000]: avg: -419.1450, min: -453.9147[2349], max: -378.8924[2215]
13: train/td_loss      [10000]: avg:  48.7018, min:  25.1488[6183], max: 851.0640[3672]
Saved model to exp/compare/square_cql_test/model13.pt
saved?: True
Mem info: used: 2.650 GB, avail: 51.093 GB, total: 62.538 GB
mean var:1.094499111175537,max:7.701678276062012,min:0.025431279093027115
[14] Time spent = 500.54 s
14: pretrain/score     : 0.00
14: data/batch_R       [10000]: avg:   0.0205, min:   0.0019[8716], max:   0.0483[7635]
14: train/actor_loss   [10000]: avg: 449.8245, min: 415.6059[3489], max: 484.6708[6392]
14: train/critic_loss  [10000]: avg:  24.4119, min:  -1.0255[5973], max: 686.4146[1664]
14: train/critic_qt    [10000]: avg: -421.6951, min: -454.3522[8472], max: -387.3825[3489]
14: train/td_loss      [10000]: avg:  48.7823, min:  23.4056[5973], max: 712.9370[1664]
Saved model to exp/compare/square_cql_test/model14.pt
saved?: True
Mem info: used: 2.649 GB, avail: 50.887 GB, total: 62.538 GB
mean var:1.220686435699463,max:8.05836296081543,min:0.026058757677674294
[15] Time spent = 498.97 s
15: pretrain/score     : 0.10
15: data/batch_R       [10000]: avg:   0.0206, min:   0.0019[1353], max:   0.0483[ 288]
15: train/actor_loss   [10000]: avg: 453.0424, min: 411.7695[4374], max: 491.0211[7850]
15: train/critic_loss  [10000]: avg:  21.9774, min:  -1.7998[8020], max: 426.0517[5998]
15: train/critic_qt    [10000]: avg: -424.7110, min: -461.2289[7850], max: -384.8160[4374]
15: train/td_loss      [10000]: avg:  46.6593, min:  23.1105[8020], max: 451.0879[5998]
Saved model to exp/compare/square_cql_test/model15.pt
saved?: True
Mem info: used: 2.649 GB, avail: 51.026 GB, total: 62.538 GB
mean var:1.0900089740753174,max:6.323612689971924,min:0.033102571964263916
[16] Time spent = 501.26 s
16: pretrain/score     : 0.00
16: data/batch_R       [10000]: avg:   0.0206, min:   0.0019[4203], max:   0.0446[6573]
16: train/actor_loss   [10000]: avg: 457.3995, min: 420.4727[1074], max: 495.5291[5077]
16: train/critic_loss  [10000]: avg:  22.3374, min:  -3.0027[ 573], max: 403.6518[7405]
16: train/critic_qt    [10000]: avg: -428.8022, min: -465.7991[5077], max: -392.0396[1074]
16: train/td_loss      [10000]: avg:  47.2939, min:  22.4932[ 573], max: 429.0412[7405]
Saved model to exp/compare/square_cql_test/model16.pt
saved?: True
Mem info: used: 2.649 GB, avail: 51.027 GB, total: 62.538 GB
mean var:1.1886377334594727,max:14.622380256652832,min:0.023484844714403152
[17] Time spent = 518.23 s
17: pretrain/score     : 0.30
17: data/batch_R       [10000]: avg:   0.0205, min:   0.0019[1896], max:   0.0463[1827]
17: train/actor_loss   [10000]: avg: 461.3515, min: 424.7053[3278], max: 495.3196[1968]
17: train/critic_loss  [10000]: avg:  22.3480, min:  -0.5777[8009], max: 252.8072[7756]
17: train/critic_qt    [10000]: avg: -432.5219, min: -466.5710[1968], max: -393.8691[3278]
17: train/td_loss      [10000]: avg:  47.5010, min:  25.0568[8009], max: 277.8519[7756]
Saved model to exp/compare/square_cql_test/model17.pt
saved?: True
Mem info: used: 2.650 GB, avail: 50.988 GB, total: 62.538 GB
mean var:1.2446238994598389,max:11.828161239624023,min:0.04330829530954361
[18] Time spent = 538.80 s
18: pretrain/score     : 0.30
18: data/batch_R       [10000]: avg:   0.0204, min:   0.0019[9773], max:   0.0465[6567]
18: train/actor_loss   [10000]: avg: 465.0504, min: 428.0214[1387], max: 501.6965[8017]
18: train/critic_loss  [10000]: avg:  21.8536, min:  -0.0925[4982], max: 300.1213[7406]
18: train/critic_qt    [10000]: avg: -435.9845, min: -471.2345[8017], max: -399.3135[1387]
18: train/td_loss      [10000]: avg:  47.2569, min:  25.1499[7367], max: 325.6736[7406]
Saved model to exp/compare/square_cql_test/model18.pt
saved?: True
Mem info: used: 2.650 GB, avail: 50.992 GB, total: 62.538 GB
mean var:1.119098424911499,max:9.755228996276855,min:0.006416033022105694
[19] Time spent = 497.91 s
19: pretrain/score     : 0.10
19: data/batch_R       [10000]: avg:   0.0204, min:   0.0019[1542], max:   0.0465[4873]
19: train/actor_loss   [10000]: avg: 467.8727, min: 429.8629[8459], max: 503.0878[4524]
19: train/critic_loss  [10000]: avg:  23.6176, min:  -1.5421[5436], max: 335.8065[6507]
19: train/critic_qt    [10000]: avg: -438.6250, min: -474.6433[4524], max: -399.4012[8459]
19: train/td_loss      [10000]: avg:  49.1738, min:  24.0978[ 852], max: 362.7625[6507]
Saved model to exp/compare/square_cql_test/model19.pt
saved?: True
Mem info: used: 2.649 GB, avail: 50.990 GB, total: 62.538 GB
